{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import pandas as pd\n",
    "from shapely.geometry import MultiLineString, LineString\n",
    "import ortools\n",
    "from shapely.ops import nearest_points\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LINK 파일 불러오기\n",
    "link_df=gpd.read_file(\".\\[2024-03-25]NODELINKDATA\\MOCT_LINK.shp\",encoding='euc-kr')\n",
    "link_df['geometry'] = link_df['geometry'].to_crs('EPSG:4326') # 위도경도 좌표계 변환\n",
    "\n",
    "# 새로운 DBF 파일 읽기\n",
    "new_df = gpd.read_file(\"2022-TM-GR-MR-LLV2 도로망(2021년 기준_세계)\\\\2022-TM-GR-MR-LLV2 도로망(2021년 기준)\\\\02. 링크\\\\ad0022_2021_GR.dbf\")\n",
    "new_df['geometry'] = new_df['geometry'].to_crs('EPSG:4326') # 위도경도 좌표계 변환\n",
    "\n",
    "link_columns_to_drop = ['UPDATEDATE', 'REMARK', 'HIST_TYPE', 'HISTREMARK','REST_VEH', 'REST_W','REST_H','REMARK','MULTI_LINK','CONNECT','C-ITS']\n",
    "link_df = link_df.drop(columns=link_columns_to_drop, errors='ignore')\n",
    "\n",
    "tempL=link_df['LINK_ID'].apply(lambda x:int(x[:3]))\n",
    "slink_df=link_df[(tempL>=100)&(tempL<=124)] ### 서울 코드 100~124\n",
    "\n",
    "# 국토교통부_전국 노드링크별 평균택시속도_20231231 (1) 파일 불러오기\n",
    "taxi_speed_df = pd.read_csv(\".\\국토교통부_전국 노드링크별 평균택시속도_20231231 (1).csv\")\n",
    "\n",
    "# '링크아이디' 열 이름을 'LINK_ID'로 변경\n",
    "taxi_speed_df = taxi_speed_df.rename(columns={'링크아이디': 'LINK_ID'})\n",
    "\n",
    "# 데이터 타입을 일치시키기 위해 LINK_ID를 문자열로 변환\n",
    "slink_df['LINK_ID'] = slink_df['LINK_ID'].astype(str)\n",
    "taxi_speed_df['LINK_ID'] = taxi_speed_df['LINK_ID'].astype(str)\n",
    "\n",
    "# 필요한 열만 남기기: LINK_ID와 평균속도\n",
    "taxi_speed_df = taxi_speed_df[['LINK_ID', '평균속도']]\n",
    "\n",
    "# slink_df와 taxi_speed_df를 LINK_ID를 기준으로 병합\n",
    "slink_df = slink_df.merge(taxi_speed_df, on='LINK_ID', how='left')\n",
    "\n",
    "# 병합 결과 확인\n",
    "slink_df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NODE 파일 불러오기\n",
    "\n",
    "node_df = gpd.read_file(\".\\[2024-03-25]NODELINKDATA\\MOCT_NODE.shp\", encoding='euc-kr')\n",
    "node_df['geometry'] = node_df['geometry'].to_crs('EPSG:4326')  # 위도경도 좌표계 변환\n",
    "\n",
    "node_columns_to_drop = ['UPDATEDATE', 'REMARK', 'HIST_TYPE', 'HISTREMARK']\n",
    "node_df = node_df.drop(columns=node_columns_to_drop, errors='ignore')\n",
    "\n",
    "tempN=node_df['NODE_ID'].apply(lambda x:int(x[:3]))\n",
    "snode_df=node_df[(tempN>=100)&(tempN<=124)] ### 서울 코드 100~124\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link 파일 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#교통망 GIS DB와 ITS 국가교통정보센터에서 쓰는 LINK_ID 일치화\n",
    "'''\n",
    "def find_nearest_geometry(target_geom, geometries):\n",
    "    if target_geom is None:\n",
    "        return None\n",
    "    nearest_geom = min(geometries, key=lambda geom: target_geom.distance(geom) if geom is not None else float('inf'))\n",
    "    return nearest_geom\n",
    "\n",
    "# 완전히 일치하는 geometry 찾기\n",
    "exact_match = gpd.sjoin(slink_df, new_df[['geometry', 'TL_DENSITY']], how='inner', predicate='within')\n",
    "exact_match = exact_match[exact_match.apply(lambda row: row['geometry'].equals(new_df.loc[row['index_right'], 'geometry']), axis=1)]\n",
    "\n",
    "# 일치하지 않는 geometry에 대해 가장 가까운 geometry 찾기\n",
    "unmatched = slink_df[~slink_df['LINK_ID'].isin(exact_match['LINK_ID'])]\n",
    "nearest_match = gpd.sjoin_nearest(unmatched, new_df[['geometry', 'TL_DENSITY']], how='left', max_distance=1000)  # max_distance 추가\n",
    "\n",
    "# 중복 제거 (LINK_ID 기준으로 첫 번째 매치만 유지)\n",
    "nearest_match = nearest_match.groupby('LINK_ID').first().reset_index()\n",
    "\n",
    "# 결과 합치기\n",
    "merged_df = pd.concat([exact_match, nearest_match])\n",
    "\n",
    "# 중복 열 제거 및 인덱스 재설정\n",
    "merged_df = merged_df.drop(columns=['index_right'], errors='ignore').reset_index(drop=True)\n",
    "\n",
    "# NaN 값 처리 (선택적)\n",
    "merged_df = merged_df.dropna(subset=['geometry'])\n",
    "\n",
    "# 결과를 slink_df에 할당\n",
    "slink_df = merged_df\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#빈 평균속도 값 NODE 꼬리물면서 찾기\n",
    "\n",
    "def fill_missing_speed_recursive(df, link_id, visited=None, depth=0):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    if link_id in visited or depth > 10:  # 깊이 제한 추가\n",
    "        return None\n",
    "    \n",
    "    visited.add(link_id)\n",
    "    row = df[df['LINK_ID'] == link_id].iloc[0]\n",
    "    \n",
    "    if pd.notnull(row['평균속도']):\n",
    "        return row['평균속도']\n",
    "    \n",
    "    # F_NODE와 일치하는 T_NODE를 가진 행들 찾기\n",
    "    matching_rows_f = df[(df['T_NODE'] == row['F_NODE']) & (df['LINK_ID'] != link_id)]\n",
    "    \n",
    "    for _, matching_row in matching_rows_f.iterrows():\n",
    "        speed = fill_missing_speed_recursive(df, matching_row['LINK_ID'], visited, depth + 1)\n",
    "        if speed is not None:\n",
    "            return speed\n",
    "    \n",
    "    # T_NODE와 일치하는 F_NODE를 가진 행들 찾기\n",
    "    matching_rows_t = df[(df['F_NODE'] == row['T_NODE']) & (df['LINK_ID'] != link_id)]\n",
    "    \n",
    "    for _, matching_row in matching_rows_t.iterrows():\n",
    "        speed = fill_missing_speed_recursive(df, matching_row['LINK_ID'], visited, depth + 1)\n",
    "        if speed is not None:\n",
    "            return speed\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fill_missing_speed(df):\n",
    "    for index, row in df[df['평균속도'].isnull()].iterrows():\n",
    "        speed = fill_missing_speed_recursive(df, row['LINK_ID'])\n",
    "        if speed is not None:\n",
    "            df.at[index, '평균속도'] = speed\n",
    "    return df\n",
    "\n",
    "# slink_df에 함수 적용\n",
    "slink_df = fill_missing_speed(slink_df)\n",
    "\n",
    "# 결과 확인\n",
    "print(slink_df[['LINK_ID', 'F_NODE', 'T_NODE', 'ROAD_RANK', '평균속도']])\n",
    "\n",
    "# 남아있는 null 값 확인\n",
    "null_count = slink_df['평균속도'].isnull().sum()\n",
    "print(f\"남아있는 null 값의 개수: {null_count}\")\n",
    "\n",
    "# 남아있는 null 값에 대해 ROAD_RANK별 평균 속도 적용\n",
    "if null_count > 0:\n",
    "    mean_speed_by_rank = slink_df.groupby('ROAD_RANK')['평균속도'].mean()\n",
    "    \n",
    "    for index, row in slink_df[slink_df['평균속도'].isnull()].iterrows():\n",
    "        slink_df.at[index, '평균속도'] = mean_speed_by_rank[row['ROAD_RANK']]\n",
    "\n",
    "    # 최종 결과 확인\n",
    "    print(\"ROAD_RANK별 평균 속도 적용 후:\")\n",
    "    print(slink_df[['LINK_ID', 'F_NODE', 'T_NODE', 'ROAD_RANK', '평균속도']])\n",
    "    \n",
    "    # 최종 null 값 확인\n",
    "    final_null_count = slink_df['평균속도'].isnull().sum()\n",
    "    print(f\"최종 남아있는 null 값의 개수: {final_null_count}\")\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 적용\n",
    "'''\n",
    "#vdr_parameter.CSV 파일 읽기\n",
    "vdr_params = pd.read_csv('vdr_parameter.CSV')\n",
    "\n",
    "# 숫자 컬럼의 쉼표 제거 및 숫자형으로 변환\n",
    "numeric_columns = ['C_L', 'C_S', 'C_U', 'ROAD_RANK_L', 'ROAD_RANK_U', 'LANES_L', 'LANES_U', 'TL_DENSITY_L', 'TL_DENSITY_U']\n",
    "for col in numeric_columns:\n",
    "    vdr_params[col] = pd.to_numeric(vdr_params[col].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# link_df의 관련 열들을 숫자형으로 변환\n",
    "slink_df['ROAD_RANK'] = pd.to_numeric(slink_df['ROAD_RANK'], errors='coerce')\n",
    "slink_df['LANES'] = pd.to_numeric(slink_df['LANES'], errors='coerce')\n",
    "slink_df['TL_DENSITY'] = pd.to_numeric(slink_df['TL_DENSITY'], errors='coerce')\n",
    "\n",
    "# 조건에 따라 VDF 값을 할당하는 함수\n",
    "def assign_vdf(row, vdr_params):\n",
    "    for _, vdr_row in vdr_params.iterrows():\n",
    "        road_rank_condition = vdr_row['ROAD_RANK_L'] < row['ROAD_RANK'] <= vdr_row['ROAD_RANK_U']\n",
    "        lanes_condition = vdr_row['LANES_L'] < row['LANES'] <= vdr_row['LANES_U']\n",
    "        \n",
    "        if row['ROAD_RANK'] in [101, 102]:\n",
    "            # ROAD_RANK가 101 또는 102인 경우 TL_DENSITY 조건을 무시\n",
    "            if road_rank_condition and lanes_condition:\n",
    "                return pd.Series({\n",
    "                    'VDF': vdr_row['VDF'],\n",
    "                    'BPR_A': vdr_row['BPR_A'],\n",
    "                    'BPR_B': vdr_row['BPR_B'],\n",
    "                    'V_L': vdr_row['V_L'],\n",
    "                    'V_S': vdr_row['V_S'],\n",
    "                    'V_U': vdr_row['V_U'],\n",
    "                    'C_L': vdr_row['C_L'],\n",
    "                    'C_S': vdr_row['C_S'],\n",
    "                    'C_U': vdr_row['C_U']\n",
    "                })\n",
    "        else:\n",
    "            # TL_DENSITY가 0인 경우 특별 처리\n",
    "            if row['TL_DENSITY'] == 0:\n",
    "                tl_density_condition = vdr_row['TL_DENSITY_L'] == 0 and vdr_row['TL_DENSITY_U'] == 0.3\n",
    "            elif pd.isna(row.get('TL_DENSITY')):\n",
    "                tl_density_condition = True  # TL_DENSITY가 NaN이면 조건을 무시\n",
    "            else:\n",
    "                tl_density_condition = vdr_row['TL_DENSITY_L'] < row['TL_DENSITY'] <= vdr_row['TL_DENSITY_U']\n",
    "            \n",
    "            if road_rank_condition and lanes_condition and tl_density_condition:\n",
    "                return pd.Series({\n",
    "                    'VDF': vdr_row['VDF'],\n",
    "                    'BPR_A': vdr_row['BPR_A'],\n",
    "                    'BPR_B': vdr_row['BPR_B'],\n",
    "                    'V_L': vdr_row['V_L'],\n",
    "                    'V_S': vdr_row['V_S'],\n",
    "                    'V_U': vdr_row['V_U'],\n",
    "                    'C_L': vdr_row['C_L'],\n",
    "                    'C_S': vdr_row['C_S'],\n",
    "                    'C_U': vdr_row['C_U']\n",
    "                })\n",
    "    \n",
    "    # 조건에 맞는 값이 없을 경우 기본값 반환\n",
    "    return pd.Series({\n",
    "        'VDF': None,\n",
    "        'BPR_A': None,\n",
    "        'BPR_B': None,\n",
    "        'V_L': None,\n",
    "        'V_S': None,\n",
    "        'V_U': None,\n",
    "        'C_L': None,\n",
    "        'C_S': None,\n",
    "        'C_U': None\n",
    "    })\n",
    "\n",
    "# slink_df에 VDF 값 할당\n",
    "new_columns = slink_df.apply(lambda row: assign_vdf(row, vdr_params), axis=1)\n",
    "slink_df = pd.concat([slink_df, new_columns], axis=1)\n",
    "\n",
    "display(slink_df)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# slink_df를 CSV 파일로 저장\n",
    "slink_df.to_csv(\"slink_df_output.csv\", index=False, encoding='utf-8-sig')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinK 시각화 함수\n",
    "\n",
    "def linechart(df):\n",
    "    m = folium.Map(location=[37.5665, 126.9780], zoom_start=15)\n",
    "    for _, row in df.iterrows():\n",
    "        if isinstance(row['geometry'], MultiLineString) and len(row['geometry'].geoms) > 1:\n",
    "            for line_string in row['geometry'].geoms:\n",
    "                coordinates = [(lat, lon) for lon, lat in line_string.coords]\n",
    "                folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "        else:\n",
    "            coordinates = [(lat, lon) for lon, lat in zip(*row['geometry'].xy)]\n",
    "            folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "    return m\n",
    "\n",
    "linechart(slink_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "display(snode_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# NODE 시각화 함수\n",
    "def node_chart(df):\n",
    "    m = folium.Map(location=[37.5665, 126.9780], zoom_start=11)\n",
    "    for _, row in df.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=2,\n",
    "            popup=row['NODE_ID'],\n",
    "            color='red',\n",
    "            fill=True\n",
    "        ).add_to(m)\n",
    "    return m\n",
    "\n",
    "# 서울 지역 NODE 시각화\n",
    "seoul_node_map = node_chart(snode_df)\n",
    "display(seoul_node_map)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 노드와 링크를 겹쳐서 시각화\n",
    "def visualize_nodes_and_links(node_df, link_df):\n",
    "    m = folium.Map(location=[37.5665, 126.9780], zoom_start=15)\n",
    "    \n",
    "    # Add links to the map\n",
    "    for _, row in link_df.iterrows():\n",
    "        if isinstance(row['geometry'], MultiLineString) and len(row['geometry'].geoms) > 1:\n",
    "            for line_string in row['geometry'].geoms:\n",
    "                coordinates = [(lat, lon) for lon, lat in line_string.coords]\n",
    "                folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "        else:\n",
    "            coordinates = [(lat, lon) for lon, lat in zip(*row['geometry'].xy)]\n",
    "            folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "    \n",
    "    # Add nodes to the map\n",
    "    for _, row in node_df.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=2,\n",
    "            popup=row['NODE_ID'],\n",
    "            color='red',\n",
    "            fill=True\n",
    "        ).add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# 시각화\n",
    "combined_map = visualize_nodes_and_links(snode_df, slink_df)\n",
    "display(combined_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPR 함수를 이용해서 교통량 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def calculate_volume(row):\n",
    "    C = row['C_S']\n",
    "    alpha = row['BPR_A']\n",
    "    beta = row['BPR_B']\n",
    "    t = row['LENGTH'] / row['평균속도']\n",
    "    t_0 = row['LENGTH'] / row['V_U']\n",
    "    \n",
    "    # BPR 함수를 이용하여 V 계산\n",
    "    if t <= t_0:\n",
    "        return 0  # 현재 통행시간이 자유 통행시간보다 작거나 같으면 교통량은 0\n",
    "    \n",
    "    V = C * ((t / t_0 - 1) / alpha) ** (1 / beta)\n",
    "    return V\n",
    "\n",
    "# slink_df에 새로운 열 'Calculated_Volume' 추가\n",
    "slink_df['Calculated_Volume'] = slink_df.apply(calculate_volume, axis=1)\n",
    "\n",
    "# 결과 확인\n",
    "print(slink_df[['LINK_ID', 'LENGTH', '평균속도', 'V_S', 'C_S', 'BPR_A', 'BPR_B', 'Calculated_Volume']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "링크에 구명 배정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "slink_df.to_csv(\"slink_df_output_with_q.csv\", index=False, encoding='utf-8-sig')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 필요한 라이브러리 import\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 도로명코드_전체 파일 읽기 (파일 경로는 실제 파일 위치에 맞게 수정해주세요)\n",
    "road_code_df = pd.read_csv(\"도로명코드_전체.csv\", encoding='euc-kr')\n",
    "\n",
    "# slink_df 읽기 (이미 있다고 가정)\n",
    "# slink_df = gpd.read_file(\"path_to_slink_file.shp\")\n",
    "\n",
    "# 도로명과 시군구명 매칭 함수\n",
    "def match_road_name(row, road_code_df):\n",
    "    matched = road_code_df[road_code_df['도로명'] == row['ROAD_NAME']]\n",
    "    if not matched.empty:\n",
    "        return matched.iloc[0]['시군구명']\n",
    "    return None\n",
    "\n",
    "# 연결된 링크를 통해 시군구명 찾기 함수\n",
    "def find_sigungu_recursive(df, link_id, visited=None, depth=0):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    if link_id in visited or depth > 10:  # 깊이 제한\n",
    "        return None\n",
    "    \n",
    "    visited.add(link_id)\n",
    "    row = df[df['LINK_ID'] == link_id].iloc[0]\n",
    "    \n",
    "    if pd.notnull(row['시군구명']):\n",
    "        return row['시군구명']\n",
    "    \n",
    "    # F_NODE와 일치하는 T_NODE를 가진 행들 찾기\n",
    "    matching_rows_f = df[(df['T_NODE'] == row['F_NODE']) & (df['LINK_ID'] != link_id)]\n",
    "    \n",
    "    for _, matching_row in matching_rows_f.iterrows():\n",
    "        sigungu = find_sigungu_recursive(df, matching_row['LINK_ID'], visited, depth + 1)\n",
    "        if sigungu is not None:\n",
    "            return sigungu\n",
    "    \n",
    "    # T_NODE와 일치하는 F_NODE를 가진 행들 찾기\n",
    "    matching_rows_t = df[(df['F_NODE'] == row['T_NODE']) & (df['LINK_ID'] != link_id)]\n",
    "    \n",
    "    for _, matching_row in matching_rows_t.iterrows():\n",
    "        sigungu = find_sigungu_recursive(df, matching_row['LINK_ID'], visited, depth + 1)\n",
    "        if sigungu is not None:\n",
    "            return sigungu\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 도로명 매칭 적용\n",
    "slink_df['시군구명'] = slink_df.apply(lambda row: match_road_name(row, road_code_df), axis=1)\n",
    "\n",
    "# 연결된 링크를 통해 시군구명 찾기\n",
    "for index, row in slink_df[slink_df['시군구명'].isnull()].iterrows():\n",
    "    sigungu = find_sigungu_recursive(slink_df, row['LINK_ID'])\n",
    "    if sigungu is not None:\n",
    "        slink_df.at[index, '시군구명'] = sigungu\n",
    "\n",
    "# 결과 확인\n",
    "print(slink_df[['LINK_ID', 'ROAD_NAME', '시군구명']])\n",
    "\n",
    "# 남아있는 null 값 확인\n",
    "null_count = slink_df['시군구명'].isnull().sum()\n",
    "print(f\"시군구명이 없는 링크 수: {null_count}\")\n",
    "slink_df.to_csv(\"slink_df_output_with_q,s.csv\", index=False, encoding='utf-8-sig')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slink_df_output.csv 파일 읽기\n",
    "slink_df = pd.read_csv('Slink_df_output_with_q,s.csv')\n",
    "\n",
    "# 만약 geometry 열이 있다면, 이를 GeoSeries로 변환\n",
    "if 'geometry' in slink_df.columns:\n",
    "    slink_df['geometry'] = gpd.GeoSeries.from_wkt(slink_df['geometry'])\n",
    "    slink_df = gpd.GeoDataFrame(slink_df, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "# 금천구 링크만 선택\n",
    "geumcheon_links = slink_df[slink_df['시군구명'] == '금천구']\n",
    "\n",
    "def bpr_inverse(speed, row):\n",
    "    t = row['LENGTH'] / speed\n",
    "    t_0 = row['LENGTH'] / row['V_U']\n",
    "    C = row['C_S']\n",
    "    V = row['Calculated_Volume'] * 0.67  # 67% of the current volume\n",
    "    alpha = row['BPR_A']\n",
    "    beta = row['BPR_B']\n",
    "    \n",
    "    return t / t_0 - (1 + alpha * (V / C) ** beta)\n",
    "\n",
    "def calculate_new_speed(row):\n",
    "    initial_guess = row['평균속도']\n",
    "    new_speed = fsolve(bpr_inverse, initial_guess, args=(row,))[0]\n",
    "    return new_speed\n",
    "\n",
    "# 새로운 속도 계산\n",
    "geumcheon_links['New_Speed'] = geumcheon_links.apply(calculate_new_speed, axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "print(geumcheon_links[['LINK_ID', '평균속도', 'New_Speed', 'Calculated_Volume']])\n",
    "\n",
    "# 평균 속도 변화 계산\n",
    "avg_speed_change = (geumcheon_links['New_Speed'].mean() - geumcheon_links['평균속도'].mean()) / geumcheon_links['평균속도'].mean() * 100\n",
    "\n",
    "print(f\"\\n평균 속도 변화: {avg_speed_change:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import folium\n",
    "from shapely import wkt\n",
    "from heapq import heappop, heappush\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 데이터 읽기\n",
    "try:\n",
    "    geumcheon_links = gpd.read_file('geumcheon_links.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    geumcheon_links = gpd.read_file('geumcheon_links.csv', encoding='euc-kr')\n",
    "\n",
    "if 'geometry' not in geumcheon_links.columns:\n",
    "    geumcheon_links['geometry'] = geumcheon_links['geometry'].apply(wkt.loads)\n",
    "    geumcheon_links = gpd.GeoDataFrame(geumcheon_links, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# 네트워크 생성\n",
    "G = nx.DiGraph()\n",
    "for _, row in geumcheon_links.iterrows():\n",
    "    G.add_edge(row['F_NODE'], row['T_NODE'], weight=float(row['LENGTH']), id=row['LINK_ID'])\n",
    "\n",
    "# k-최단 경로 찾기 (단순 예제)\n",
    "def k_shortest_paths(graph, source, target, k, weight='weight'):\n",
    "    paths = []\n",
    "    queue = [(0, source, [])]\n",
    "    \n",
    "    while queue and len(paths) < k:\n",
    "        (cost, node, path) = heappop(queue)\n",
    "        if node in path:\n",
    "            continue\n",
    "        path = path + [node]\n",
    "        if node == target:\n",
    "            paths.append((cost, path))\n",
    "        else:\n",
    "            for neighbor, data in graph[node].items():\n",
    "                heappush(queue, (cost + data.get(weight, 1), neighbor, path))\n",
    "    return [p[1] for p in paths]\n",
    "\n",
    "# 사용자 균형 배정 함수\n",
    "def user_equilibrium_with_paths(G, od_pairs, k, max_iter=100, convergence=1e-6, n_jobs=-1):\n",
    "    flow_dict = {(u, v): 0.0 for u, v in G.edges()}\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        old_flow = flow_dict.copy()\n",
    "        \n",
    "        # od_pairs 각 쌍에 대해 병렬처리\n",
    "        results = Parallel(n_jobs=n_jobs, backend='threading')(\n",
    "            delayed(process_od_pair)(G, origin, destination, k)\n",
    "            for origin, destination in od_pairs\n",
    "        )\n",
    "        \n",
    "        # 결과 합산\n",
    "        # process_od_pair 함수는 경로 리스트를 반환하며 경로별로 flow를 균등 분배했다고 가정\n",
    "        # demand를 1로 가정했으니 paths 수만큼 1/len(paths)를 add\n",
    "        for paths in results:\n",
    "            if paths:\n",
    "                flow_per_path = 1.0 / len(paths)\n",
    "                for path in paths:\n",
    "                    for i in range(len(path) - 1):\n",
    "                        u, v = path[i], path[i+1]\n",
    "                        flow_dict[(u, v)] += flow_per_path\n",
    "        \n",
    "        # 수렴 확인\n",
    "        if all(abs(flow_dict[edge] - old_flow[edge]) < convergence for edge in flow_dict):\n",
    "            break\n",
    "    \n",
    "    return flow_dict\n",
    "\n",
    "def process_od_pair(G, origin, destination, k):\n",
    "    paths = k_shortest_paths(G, origin, destination, k)\n",
    "    return paths\n",
    "\n",
    "# 전체 통행 시간 계산\n",
    "def calculate_total_travel_time(G, flow_dict):\n",
    "    total_time = 0\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        flow = flow_dict.get((u, v), 0)\n",
    "        total_time += flow * data['weight']\n",
    "    return total_time\n",
    "\n",
    "# 브라에스 역설 확인\n",
    "def check_braess_paradox(G, geumcheon_links, k=5):\n",
    "    nodes = list(G.nodes())\n",
    "    if len(nodes) < 2:\n",
    "        print(\"그래프에 충분한 노드가 없습니다.\")\n",
    "        return []\n",
    "    origin = nodes[0]\n",
    "    destination = nodes[-1]\n",
    "    od_pairs = [(origin, destination)]\n",
    "    \n",
    "    print(f\"선택된 OD 쌍: {od_pairs}\")\n",
    "    \n",
    "    # 초기 사용자 균형 상태 계산 (병렬 사용)\n",
    "    initial_flow = user_equilibrium_with_paths(G, od_pairs, k, n_jobs=-1)\n",
    "    initial_total_time = calculate_total_travel_time(G, initial_flow)\n",
    "    \n",
    "    paradox_links = []\n",
    "    \n",
    "    for u, v, data in list(G.edges(data=True)):\n",
    "        G.remove_edge(u, v)  # 링크 제거\n",
    "        try:\n",
    "            new_flow = user_equilibrium_with_paths(G, od_pairs, k, n_jobs=-1)\n",
    "            new_total_time = calculate_total_travel_time(G, new_flow)\n",
    "            if new_total_time < initial_total_time:\n",
    "                paradox_links.append((u, v, data['id'], initial_total_time - new_total_time))\n",
    "        except nx.NetworkXNoPath:\n",
    "            pass\n",
    "        G.add_edge(u, v, **data)  # 링크 복구\n",
    "    \n",
    "    return paradox_links\n",
    "\n",
    "# 실행\n",
    "paradox_links = check_braess_paradox(G, geumcheon_links, k=5)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"브라에스 역설이 발생하는 링크:\")\n",
    "for u, v, link_id, time_diff in paradox_links:\n",
    "    print(f\"Link {link_id}: {u} -> {v}, 시간 단축: {time_diff:.2f} 초\")\n",
    "\n",
    "# 지도 시각화\n",
    "m = folium.Map(location=[37.4563, 126.8955], zoom_start=12)\n",
    "\n",
    "# 모든 링크 추가\n",
    "for _, row in geumcheon_links.iterrows():\n",
    "    geom = wkt.loads(row['geometry'])\n",
    "    coords = list(geom.coords)\n",
    "    folium.PolyLine(locations=[(y, x) for x, y in coords], color='blue', weight=2, opacity=0.8).add_to(m)\n",
    "\n",
    "# 브라에스 역설 링크 강조\n",
    "for u, v, link_id, _ in paradox_links:\n",
    "    link_data = geumcheon_links[geumcheon_links['LINK_ID'] == link_id]\n",
    "    if not link_data.empty:\n",
    "        geom = wkt.loads(link_data['geometry'].values[0])\n",
    "        coords = list(geom.coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in coords], color='red', weight=4, opacity=1).add_to(m)\n",
    "\n",
    "m.save('geumcheon_braess_paradox_map.html')\n",
    "print(\"지도 파일이 'geumcheon_braess_paradox_map.html'로 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
